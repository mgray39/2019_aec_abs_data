{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2febd722-efc6-492a-bb6b-be8e34530c88",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "First get the 2019 election data  in and restructure it according to the following schema:\n",
    "\n",
    "![schema](diagrams/schema.jpg)\n",
    "\n",
    "Add key metrics from the ABS regarding electorates to the electorate data. Also join in the SA2 data for the polling places and include a similar set of variables. Consider the inclusion of crime data. Use geonames to geocode crime data. Also restructure it. It's disgusting.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292d310-01d0-47a2-98b8-4db937e1d0ea",
   "metadata": {},
   "source": [
    "## How it is made\n",
    "\n",
    "Things you will need:\n",
    "\n",
    "1. Australian Electoral Commission Data for 2019. Files available for download from [here](https://results.aec.gov.au/24310/Website/HouseDownloadsMenu-24310-Csv.htm)\n",
    "   1. Each of the \"Distribution of Preferences by Polling Place - {state} files were downloaded nad expanded into a series of files targetted in file_list\n",
    "   2. Party Data from the Political Parties file was used for party_file_path\n",
    "   3. Polling places file was used for polling_place_file_path\n",
    "   4. Nominations by Division was used for division data.\n",
    "   5. The National List of Candidates was used as input for candidate_file_path\n",
    "      1. This file was manually gender coded based on known genders of common names (this country, for all its multiculturalism, has many Davids, Nicoles and Dougs)\n",
    "      2. Where the gender of was ambiguous to me (either because it was not from among common English names or because it was ambiguous (consider Chris, Shane etc)) I used google searching to find images of candidates where possible and assign their apparent gender.\n",
    "2. Australian Bureau of Statistics' Australian Statistical Geographic Standard 2016 Edition SA2 shape file\n",
    "   1. Specifically [this file (WARNING: Will commence download as link targets .zip)](https://www.abs.gov.au/AUSSTATS/subscriber.nsf/log?openagent&1270055001_sa2_2016_aust_shape.zip&1270.0.55.001&Data%20Cubes&A09309ACB3FA50B8CA257FED0013D420&0&July%202016&12.07.2016&Latest)\n",
    "   2. For general information see [this](https://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.001July%202016?OpenDocument) link\n",
    "3. Australian Bureau of Statistics \"Discover Your Electorate\" data (see [here](https://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/2082.02019))\n",
    "   1. Used as the basis for electorate_statistics_file_path but essentially removed from excel format and dumped into spreadsheet\n",
    "   2. Download original spreadsheet [here](https://www.abs.gov.au/AUSSTATS/subscriber.nsf/log?openagent&commonwealth%20electorate%20data.xls&2082.0&Data%20Cubes&BDBB9991BD7E99E8CA2583AF0071A786&0&2019&01.03.2019&Latest)\n",
    "   3. Data is straight copy and pasted but column names have been rationalised.\n",
    "      1. variables begin with either pc_ (percent) or aud_ (Australian Dollars)\n",
    "      2. pc_ variables are then grouped by type - age, dwelling, occupation, background, family, employment_educ\n",
    "      3. Abrieviations: \n",
    "         1. employment_educ - employment, education or training engagement rate\n",
    "         2. atsi - Aboriginal or Torres Strait Islander (Australian First Nations peoples)\n",
    "         3. family_nuclear - a family with a couple and children\n",
    "      4. withheld is used where ABS data indicated that this information was not stated or in some cases too vague. \"vague\" is used where ABS specifically indicates that the information was provided but with insufficient detail to categorise. \n",
    "      \n",
    "4. Australian Bureau of Statistics General Community Profile SA2 dataset for Australia\n",
    "   1. General page used to access was [here](https://www.abs.gov.au/census/find-census-data/datapacks?release=2016&product=GCP&geography=SA2&header=S)\n",
    "   2. [This file](https://www.abs.gov.au/census/find-census-data/datapacks/download/2016_GCP_SA2_for_AUS_short-header.zip) was used to download the data for the 2016 release.\n",
    "   3. Files used are contained in the script below. To identify where an item comes from read the file_path variable for each of the sa2 files as this will give you a good idea what file number to look up. The replacement_dict for each file used for cleaning will give you a good idea what variables I am targetting for inclusion. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485e1ae4-94b3-48b6-b1f2-7ee40381074f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitchell/.local/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f31364d-134b-40c4-8a5d-99b2f46caf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'outputs/'\n",
    "\n",
    "file_list_house_of_reps_data = glob.glob('house_of_reps/*/*.csv')\n",
    "\n",
    "party_file_path = 'misc/hor/parties.csv'\n",
    "\n",
    "polling_place_file_path = 'misc/hor/polling_places.csv'\n",
    "\n",
    "sa2_data_file_path = '../../geospatial/sa2_2016/SA2_2016_AUST.shp'\n",
    "\n",
    "nominations_by_division_file_path = 'misc/hor/division_nomination.csv'\n",
    "\n",
    "electorate_statistics_file_path = '../../geospatial/ABS_2802_0_electorate_data_2019.csv'\n",
    "\n",
    "candidate_file_path = 'misc/hor/members_nominated.csv'\n",
    "\n",
    "sa2_age_total_population_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G01_AUS_SA2.csv'\n",
    "\n",
    "sa2_migration_timeframe_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G10C_AUS_SA2.csv'\n",
    "\n",
    "sa2_occupation_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G57B_AUS_SA2.csv'\n",
    "\n",
    "sa2_university_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G15_AUS_SA2.csv'\n",
    "\n",
    "\n",
    "sa2_labourforce_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G40_AUS_SA2.csv'\n",
    "\n",
    "\n",
    "sa2_religion_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G14_AUS_SA2.csv'\n",
    "\n",
    "sa2_industry_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G53A_AUS_SA2.csv'\n",
    "\n",
    "\n",
    "sa2_family_composition_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G25_AUS_SA2.csv'\n",
    "\n",
    "\n",
    "sa2_dwelling_type_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G33_AUS_SA2.csv'\n",
    "\n",
    "sa2_medians_file_path = '../../geospatial/2016_SA2_Community_profile/2016 Census GCP Statistical Area 2 for AUST/2016Census_G02_AUS_SA2.csv'\n",
    "\n",
    "\n",
    "preference_distribution_column_counts_dict = {'StateAb': 'state',\n",
    "                                              'DivisionId': 'division_id',\n",
    "                                              'DivisionNm': 'division_name',\n",
    "                                              'PPId': 'polling_place_id',\n",
    "                                              'PPNm': 'polling_place_name',\n",
    "                                              'CountNum': 'round',\n",
    "                                              'CandidateId': 'candidate_id',\n",
    "                                              'Surname': 'candidate_surname',\n",
    "                                              'PartyAb': 'party_code',\n",
    "                                              'CalculationValue': 'preference_count'}\n",
    "\n",
    "\n",
    "preference_distribution_column_count_transfer_dict = {'PPId': 'polling_place_id',\n",
    "                                                      'PPNm': 'polling_place_name',\n",
    "                                                      'DivisionId':'division_id',\n",
    "                                                      'CountNum': 'round',\n",
    "                                                      'CandidateId': 'candidate_id',\n",
    "                                                      'Surname': 'candidate_surname',\n",
    "                                                      'PartyAb': 'party_code',\n",
    "                                                      'CalculationValue': 'transfer_count'}\n",
    "\n",
    "\n",
    "parties_df_replace_dict = {'StateAb': 'state',\n",
    "                           'PartyAb': 'party_code',\n",
    "                           'PartyNm': 'party_name'}\n",
    "\n",
    "\n",
    "polling_place_rename_dict = {'State': 'state',\n",
    "                             'DivisionID': 'division_id', \n",
    "                             'PollingPlaceID':'polling_place_id',\n",
    "                             'PollingPlaceTypeID':'polling_place_type_id',\n",
    "                             'PollingPlaceNm': 'polling_place_name',\n",
    "                             'PremisesNm': 'premises',\n",
    "                             'Latitude':'latitude',\n",
    "                             'Longitude': 'longitude',\n",
    "                             'geometry': 'geometry'}\n",
    "\n",
    "division_rename_dict = {'DivisionId': 'division_id',\n",
    "                        'StateAb': 'state',\n",
    "                        'DivisionNm': 'division_name',\n",
    "                        'Enrolment': 'voter_count',\n",
    "                        'Demographic': 'demographic',\n",
    "                        'Nominations': 'candidate_count'}\n",
    "\n",
    "candidate_df_replace_dict = {'PartyAb':'party_code',\n",
    "                             'CandidateID': 'candidate_id',\n",
    "                             'Surname':'candidate_surname',\n",
    "                             'GivenNm':'candidate_given_names',\n",
    "                             'Gender': 'gender'}\n",
    "\n",
    "sa2_2016_rename_dict = {'SA2_MAIN16': 'SA2_MAIN16',\n",
    "                        'SA2_NAME16': 'sa2_name',\n",
    "                        'geometry': 'geometry'}\n",
    "\n",
    "sa2_medians_replacement_dict = {'SA2_MAINCODE_2016':'SA2_MAIN16',\n",
    "                                'Median_age_persons': 'median_age',\n",
    "                                'Median_mortgage_repay_monthly': 'aud_median_monthly_mortgage_payment',\n",
    "                                'Median_rent_weekly': 'aud_median_weekly_rent',\n",
    "                                'Median_tot_hhd_inc_weekly': 'aud_median_weekly_household_income'}\n",
    "\n",
    "sa2_age_total_population_rename_dict = {'SA2_MAINCODE_2016':'SA2_MAIN16',\n",
    "                                        'Tot_P_P':'count_persons',\n",
    "                                        'Tot_P_M':'count_male_persons',\n",
    "                                        'Tot_P_F':'count_female_persons',  \n",
    "                                        'Age_0_4_yr_P': 'count_age_0_4',\n",
    "                                        'Age_5_14_yr_P': 'count_age_5_14',\n",
    "                                        'Age_15_19_yr_P': 'count_age_15_19',\n",
    "                                        'Age_20_24_yr_P': 'count_age_20_24',\n",
    "                                        'Age_25_34_yr_P': 'count_age_25_34',\n",
    "                                        'Age_35_44_yr_P': 'count_age_35_44',\n",
    "                                        'Age_45_54_yr_P': 'count_age_45_54',\n",
    "                                        'Age_55_64_yr_P': 'count_age_55_64',\n",
    "                                        'Age_65_74_yr_P': 'count_age_65_74',\n",
    "                                        'Age_75_84_yr_P': 'count_age_75_84',\n",
    "                                        'Age_85ov_P': 'count_age_over_85',\n",
    "                                        'Indigenous_P_Tot_P': 'count_atsi',\n",
    "                                        'Birthplace_Australia_P': 'count_birthplace_au',\n",
    "                                        'Birthplace_Elsewhere_P': 'count_born_overseas',\n",
    "                                        'Lang_spoken_home_Eng_only_P': 'count_english_at_home',\n",
    "                                        'Lang_spoken_home_Oth_Lang_P': 'count_linguistically_diverse',\n",
    "                                        'Australian_citizen_P': 'count_au_citizens',\n",
    "                                        'High_yr_schl_comp_Yr_12_eq_P': 'count_grade_12_completed'}\n",
    "\n",
    "sa2_migration_timeframe_replacement_dict = {'SA2_MAINCODE_2016': 'SA2_MAIN16', \n",
    "                                            'Tot_2006_2010':'count_migration_2006_2010', \n",
    "                                            'Tot_2011':'count_migration_2011', \n",
    "                                            'Tot_2012':'count_migration_2012', \n",
    "                                            'Tot_2013':'count_migration_2013', \n",
    "                                            'Tot_2014': 'count_migration_2014', \n",
    "                                            'Tot_2015': 'count_migration_2015', \n",
    "                                            'Tot_2016':'count_migration_2016'}\n",
    "\n",
    "sa2_university_replacement_dict = {'SA2_MAINCODE_2016': 'SA2_MAIN16',\n",
    "                                   'Uni_other_Tert_Instit_Tot_P':'count_university_students'}\n",
    "\n",
    "sa2_labourforce_replacement_dict = {'SA2_MAINCODE_2016': 'SA2_MAIN16',\n",
    "                                    'Percent_Unem_loyment_M': 'pc_unemployment_male',\n",
    "                                    'Percent_Unem_loyment_F': 'pc_unemployment_female',\n",
    "                                    'Percent_Unem_loyment_P': 'pc_unemployment_all',\n",
    "                                    'Percnt_LabForc_prticipation_M':'pc_labourforce_participation_male',\n",
    "                                    'Percnt_LabForc_prticipation_F': 'pc_labourforce_participation_female',\n",
    "                                    'Percnt_LabForc_prticipation_P': 'pc_labourforce_participation_all'}\n",
    "\n",
    "sa2_religion_replacement_dict = {'SA2_MAINCODE_2016': 'SA2_MAIN16',\n",
    "                                 'Buddhism_P': 'count_religion_buddhism',\n",
    "                                 'Christianity_Tot_P': 'count_religion_christianity',\n",
    "                                 'Hinduism_P': 'count_religion_hinduism',\n",
    "                                 'Islam_P': 'count_religion_islam',\n",
    "                                 'Judaism_P': 'count_religion_judaism',\n",
    "                                 'Other_Religions_Tot_P': 'count_religion_other',\n",
    "                                 'SB_OSB_NRA_Tot_P': 'count_religion_secular_spiritual_non_religious',\n",
    "                                 'Religious_affiliation_ns_P': 'count_religion_withheld',\n",
    "                                 'Tot_P': 'total_for_religion'}\n",
    "\n",
    "sa2_industry_replacement_dict = {'SA2_MAINCODE_2016': 'SA2_MAIN16',\n",
    "                                 'Agri_for_fish_Tot':'count_industry_agriculture_forestry_fisheries',\n",
    "                                 'Mining_Tot': 'count_industry_mining',\n",
    "                                 'Manufacturing_Tot': 'count_industry_manufacturing',\n",
    "                                 'El_Gas_W_W_Tot': 'count_industry_elect_gas_water_waste',\n",
    "                                 'Construction_Tot': 'count_industry_construction',\n",
    "                                 'WhlesaleTde_Tot': 'count_industry_wholesale_trade',\n",
    "                                 'RetTde_Tot': 'count_industry_retail_trade',\n",
    "                                 'Acom_food_scs_Tot':'count_industry_accomodation_food_service',\n",
    "                                 'Trans_po_wh_Tot': 'count_industry_transport_postal_warehouse',\n",
    "                                 'Infon_med_tel_Tot': 'count_industry_information_telecomm_media',\n",
    "                                 'Fin_and_ins_s_Tot': 'count_industry_finance_insurance',\n",
    "                                 'Rent_hi_re_es_Tot': 'count_industry_hiring_real_estate',\n",
    "                                 'Prof_sci_tec_Tot': 'count_industry_professional_scientific_technical',\n",
    "                                 'Admin_sup_s_Tot': 'count_industry_admin_support',\n",
    "                                 'Pub_adm_sfty_Tot': 'count_industry_public_admin_safety',\n",
    "                                 'Educ_training_Tot': 'count_industry_education_training',\n",
    "                                 'Hlth_care_soc_Tot': 'count_industry_health_care_social',\n",
    "                                 'ArtRecreatTot': 'count_industry_arts_recreation',\n",
    "                                 'Other_scs_Tot': 'count_industry_other_services',\n",
    "                                 'ID_NS_Tot': 'count_industry_witheld'}\n",
    "\n",
    "\n",
    "sa2_occupation_replacement_dict = {'SA2_MAINCODE_2016': 'SA2_MAIN16',\n",
    "                                   'P_Tot_Managers': 'count_occupation_manager',\n",
    "                                   'P_Tot_Professionals': 'count_occupation_professional', \n",
    "                                   'P_Tot_TechnicTrades_W': 'count_occupation_technician', \n",
    "                                   'P_Tot_CommunPersnlSvc_W': 'count_occupation_community_personal_service',\n",
    "                                   'P_Tot_ClericalAdminis_W': 'count_occupation_clerical',\n",
    "                                   'P_Tot_Sales_W': 'count_occupation_sales',\n",
    "                                   'P_Tot_Mach_oper_drivers': 'count_occupation_machinery_operation',\n",
    "                                   'P_Tot_Labourers': 'count_occupation_labourer',\n",
    "                                   'P_Tot_Occu_ID_NS' : 'count_occupation_witheld',\n",
    "                                   'P_Tot_Tot' : 'total_for_occupations'}\n",
    "\n",
    "sa2_family_composition_replacement_dict = {'SA2_MAINCODE_2016': 'SA2_MAIN16',\n",
    "                                        'CF_no_children_F': 'count_family_couple_no_children',\n",
    "                                        'CF_Total_F': 'count_family_nuclear', \n",
    "                                        'OPF_Total_F': 'count_family_single_parent', \n",
    "                                        'Other_family_F': 'count_family_other', \n",
    "                                        'Total_F': 'total_families'}\n",
    "\n",
    "\n",
    "sa2_dwelling_type_replacement_dict = {'SA2_MAINCODE_2016':'SA2_MAIN16',\n",
    "                                      'O_OR_Total': 'count_dwelling_owned',\n",
    "                                      'O_MTG_Total': 'count_dwelling_mortgaged',\n",
    "                                      'R_Tot_Total': 'count_dwelling_rented',\n",
    "                                      'Oth_ten_type_Total':'count_dwelling_other',\n",
    "                                      'Ten_type_NS_Total': 'count_dwelling_witheld',\n",
    "                                      'Total_Total':'total_dwellings'}\n",
    "\n",
    "\n",
    "polling_place_crs = 'EPSG:4283'\n",
    "\n",
    "\n",
    "def read_preference_distribution_files(file_list: list = file_list_house_of_reps_data) -> pd.DataFrame:\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        df_list.append(pd.read_csv(file, skiprows=1))\n",
    "    \n",
    "    preference_distribution_df = pd.concat(df_list)\n",
    "    \n",
    "    return preference_distribution_df\n",
    "\n",
    "\n",
    "def clean_preference_distribution_counts_df(df: pd.DataFrame, column_dict: dict = preference_distribution_column_counts_dict) -> pd.DataFrame:\n",
    "    \n",
    "    df = (df\n",
    "          .query(\"CalculationType == 'Preference Count'\")\n",
    "          .pipe(drop_and_rename_columns, column_dict)\n",
    "          .assign(max_round = lambda df: (df[['division_id','round']]\n",
    "                                          .groupby('division_id')\n",
    "                                          .transform('max')\n",
    "                                          .rename(columns = {'round':'max_round'})),\n",
    "                  is_final_round = lambda df: df['max_round']==df['round'])\n",
    "          .drop(columns = ['max_round'])\n",
    "          .query('preference_count!=0'))\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "def clean_preference_distribution_count_transfers_df(df: pd.DataFrame, \n",
    "                                                     column_dict: dict = preference_distribution_column_count_transfer_dict) -> pd.DataFrame:\n",
    "    \n",
    "    eliminated_rename_dict = {'candidate_id': 'eliminated_candidate_id',\n",
    "                              'candidate_surname': 'eliminated_candidate_surname',\n",
    "                              'party_code': 'eliminated_party_code'}\n",
    "    \n",
    "    gaining_rename_dict =  {'candidate_id': 'gaining_candidate_id',\n",
    "                            'candidate_surname': 'gaining_candidate_surname',\n",
    "                            'party_code': 'gaining_party_code'}\n",
    "    \n",
    "    df = (df\n",
    "          .query(\"CalculationType == 'Transfer Count'\")\n",
    "          .pipe(drop_and_rename_columns, column_dict))\n",
    "    \n",
    "    \n",
    "    eliminated_df = (df\n",
    "                     .query('transfer_count<0')\n",
    "                     .rename(columns = eliminated_rename_dict)\n",
    "                     .assign(eliminated_candidate_total_value = lambda df: df['transfer_count']*-1)\n",
    "                     .drop(columns = ['transfer_count']))\n",
    "    \n",
    "    \n",
    "    gaining_df = (df\n",
    "                  .query('transfer_count>0')\n",
    "                  .rename(columns = gaining_rename_dict))\n",
    "    \n",
    "    \n",
    "    rejoined_df = (gaining_df\n",
    "                   .merge(eliminated_df, how = 'inner', on = ['polling_place_id', 'polling_place_name','division_id', 'round']))\n",
    "    \n",
    "    return rejoined_df\n",
    "\n",
    "\n",
    "def read_and_clean_electorate_data(nominations_by_division_file_path: str = nominations_by_division_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(nominations_by_division_file_path, skiprows=1)\n",
    "          .pipe(drop_and_rename_columns, division_rename_dict))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_enriched_electorate_data(electorate_statistics_file_path: str = electorate_statistics_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    electorate_statistics = pd.read_csv(electorate_statistics_file_path)\n",
    "    \n",
    "    electorate_data = read_and_clean_electorate_data()\n",
    "    \n",
    "    enriched_electorate_data = electorate_data.merge(electorate_statistics, how = 'inner', on ='division_name')\n",
    "    \n",
    "    return enriched_electorate_data\n",
    "\n",
    "\n",
    "def read_and_clean_party_df(party_file_path: str = party_file_path, column_rename_dict: dict = parties_df_replace_dict):\n",
    "    \n",
    "    df = (pd.read_csv('misc/hor/parties.csv', skiprows=1)\n",
    "          .pipe(drop_and_rename_columns, column_rename_dict))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_candidate_df(candidate_file_path: str = candidate_file_path, column_rename_dict: dict = candidate_df_replace_dict) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(candidate_file_path, skiprows=1)\n",
    "          .pipe(drop_and_rename_columns, column_rename_dict))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_enriched_polling_place_data()-> pd.DataFrame:\n",
    "    \n",
    "    polling_place = read_and_clean_polling_place_data()\n",
    "    \n",
    "    sa2_2016_data = read_and_clean_2016_sa2_data()\n",
    "    \n",
    "    polling_place_enriched = (polling_place\n",
    "                              .sjoin(sa2_2016_data, how ='left')\n",
    "                              .drop(columns = ['geometry', 'index_right']))\n",
    "    \n",
    "    return polling_place_enriched\n",
    "\n",
    "\n",
    "def read_and_clean_polling_place_data(polling_place_file_path: str = polling_place_file_path,\n",
    "                                      polling_place_crs: str = polling_place_crs,\n",
    "                                      polling_place_rename_dict: dict = polling_place_rename_dict) -> gpd.GeoDataFrame:\n",
    "    \n",
    "    gdf = (gpd.GeoDataFrame(pd.read_csv(polling_place_file_path, skiprows=1))\n",
    "           .assign(geometry = lambda df: gpd.points_from_xy(df['Longitude'], df['Latitude'], crs = polling_place_crs))\n",
    "           .pipe(drop_and_rename_columns, polling_place_rename_dict))\n",
    "    \n",
    "    return gdf\n",
    "\n",
    "\n",
    "def read_and_clean_2016_sa2_data(sa2_data_file_path: str = sa2_data_file_path,\n",
    "                                 sa2_2016_rename_dict = sa2_2016_rename_dict) -> gpd.GeoDataFrame:\n",
    "    \n",
    "    df = (gpd.read_file(sa2_data_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_2016_rename_dict))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "## Low level SA2 statistical data prep functions\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "def read_and_clean_sa2_medians_data(sa2_medians_file_path: str = sa2_medians_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_medians_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_medians_replacement_dict))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_age_total_population_data(sa2_age_total_population_file_path: str = sa2_age_total_population_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    list_over_20_columns = ['count_age_20_24',\n",
    "                            'count_age_25_34',\n",
    "                            'count_age_35_44',\n",
    "                            'count_age_45_54',\n",
    "                            'count_age_55_64',\n",
    "                            'count_age_65_74',\n",
    "                            'count_age_75_84',\n",
    "                            'count_age_over_85']\n",
    "    \n",
    "    sum_string = '+'.join(list_over_20_columns) \n",
    "    \n",
    "    df = (pd.read_csv(sa2_age_total_population_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_age_total_population_rename_dict)\n",
    "          .assign(count_age_over_20 = lambda df: df.eval(sum_string),\n",
    "                  high_school_completion_rate = lambda df: df['count_grade_12_completed']/df['count_age_over_20'])\n",
    "          .drop(columns = ['count_age_over_20', 'count_grade_12_completed'])\n",
    "          .pipe(transform_all_count_variables_to_pc_variables, ignore_variable_list = ['SA2_MAIN16','high_school_completion_rate']))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_dwelling_data(sa2_dwelling_type_file_path: str = sa2_dwelling_type_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_dwelling_type_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_dwelling_type_replacement_dict)\n",
    "          .pipe(transform_all_count_variables_to_pc_variables, pc_basis_variable = 'total_dwellings'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_family_composition_data(sa2_family_composition_file_path: str = sa2_family_composition_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_family_composition_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_family_composition_replacement_dict)\n",
    "          .pipe(transform_all_count_variables_to_pc_variables, pc_basis_variable = 'total_families'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_migration_timeframe_data(sa2_migration_timeframe_file_path: str = sa2_migration_timeframe_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_migration_timeframe_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_migration_timeframe_replacement_dict)\n",
    "          .set_index(['SA2_MAIN16']).sum(axis=1)\n",
    "          .reset_index()\n",
    "          .rename(columns = {0:'count_migrated_since_2006'}))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_occupation_data(sa2_occupation_file_path: str = sa2_occupation_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_occupation_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_occupation_replacement_dict)\n",
    "          .pipe(transform_all_count_variables_to_pc_variables, pc_basis_variable = 'total_for_occupations'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_industry_data(sa2_industry_file_path: str = sa2_industry_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_industry_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_industry_replacement_dict)\n",
    "          .assign(total_for_industry = lambda df: (df\n",
    "                                                   .fillna(0)\n",
    "                                                   .set_index('SA2_MAIN16')\n",
    "                                                   .sum(axis=1).values))\n",
    "          .pipe(transform_all_count_variables_to_pc_variables, pc_basis_variable = 'total_for_industry'))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def read_and_clean_sa2_university_data(sa2_university_file_path: str = sa2_university_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_university_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_university_replacement_dict))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_labourforce_data(sa2_labourforce_file_path: str = sa2_labourforce_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_labourforce_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_labourforce_replacement_dict))\n",
    "    \n",
    "    columns_for_division_list = [column for column in df.columns if column!='SA2_MAIN16']\n",
    "    \n",
    "    for column in columns_for_division_list:\n",
    "        \n",
    "        df[column] = df[column]/100\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def read_and_clean_sa2_religion_data(sa2_religion_file_path: str = sa2_religion_file_path) -> pd.DataFrame:\n",
    "    \n",
    "    df = (pd.read_csv(sa2_religion_file_path)\n",
    "          .pipe(drop_and_rename_columns, sa2_religion_replacement_dict)\n",
    "          .pipe(transform_all_count_variables_to_pc_variables, pc_basis_variable = 'total_for_religion'))\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Prepare SA2 statistical data.\n",
    "\n",
    "Prepares the SA2 statistical data records.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sa2_function_list = [read_and_clean_sa2_dwelling_data, \n",
    "                     read_and_clean_sa2_family_composition_data,\n",
    "                     read_and_clean_sa2_migration_timeframe_data,\n",
    "                     read_and_clean_sa2_occupation_data,\n",
    "                     read_and_clean_sa2_industry_data,\n",
    "                     read_and_clean_sa2_university_data,\n",
    "                     read_and_clean_sa2_labourforce_data,\n",
    "                     read_and_clean_sa2_religion_data]\n",
    "\n",
    "def prepare_sa2_statistics_data(function_list: list = sa2_function_list) -> pd.DataFrame:\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for function in function_list:\n",
    "        if len(df)==0:\n",
    "            df = function()\n",
    "        else:\n",
    "            additional_df = function()\n",
    "            df = df.merge(additional_df, how ='outer', on = 'SA2_MAIN16')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Utility Functions\n",
    "\"\"\"\n",
    "\n",
    "def transform_all_count_variables_to_pc_variables(df: pd.DataFrame, \n",
    "                                                  pc_basis_variable:str = 'count_persons', \n",
    "                                                  ignore_variable_list: list = ['SA2_MAIN16']) -> pd.DataFrame:\n",
    "    \n",
    "    non_target_columns = ignore_variable_list + [pc_basis_variable]\n",
    "    \n",
    "    target_columns = [column for column in df.columns if column not in non_target_columns]\n",
    "    \n",
    "    for target_column_name in target_columns:\n",
    "        \n",
    "        new_column_name = target_column_name.replace('count','pc')\n",
    "        \n",
    "        df = (df\n",
    "              .assign(dummy_column = lambda df: df[target_column_name]/df[pc_basis_variable])\n",
    "              .rename(columns = {'dummy_column':new_column_name})\n",
    "              .drop(columns = [target_column_name]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_and_rename_columns(df: pd.DataFrame, drop_and_rename_dict: dict) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    This function essentially says if you want to rename only the columns that you want to keep, just wrap the rename dict with this function and save yourself a line...\n",
    "    but does so by writing an additional function but damn it was getting repetitive.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    keep_only_keys_list = list(drop_and_rename_dict.keys())\n",
    "    \n",
    "    df = (df[keep_only_keys_list]\n",
    "          .rename(columns = drop_and_rename_dict))\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Main Function\n",
    "\n",
    "Calls Multiple sub functions to execute routine\n",
    "\"\"\"\n",
    "\n",
    "def main(output_file_path: str = output_file_path) -> None:\n",
    "    \n",
    "    write_options = {'encoding': 'utf-8',\n",
    "                     'index': False}\n",
    "    \n",
    "    preference_data = (read_preference_distribution_files()\n",
    "                       .pipe(clean_preference_distribution_counts_df)\n",
    "                       .to_csv(f'{output_file_path}election_count.csv', **write_options))\n",
    "    \n",
    "    transfer_data = (read_preference_distribution_files()\n",
    "                     .pipe(clean_preference_distribution_count_transfers_df)\n",
    "                     .to_csv(f'{output_file_path}count_transfers.csv', **write_options))\n",
    "    \n",
    "    parties_df = (read_and_clean_party_df()\n",
    "                  .to_csv(f'{output_file_path}political_parties.csv', **write_options))\n",
    "    \n",
    "    polling_place = (pd.DataFrame(prepare_enriched_polling_place_data())\n",
    "                     .to_csv(f'{output_file_path}polling_places.csv', **write_options))\n",
    "    \n",
    "    electorates = (prepare_enriched_electorate_data()\n",
    "                 .to_csv(f'{output_file_path}electorates.csv', **write_options))\n",
    "    \n",
    "    candidates = (read_and_clean_candidate_df()\n",
    "                  .to_csv(f'{output_file_path}candidates.csv', **write_options))\n",
    "    \n",
    "    sa2_statistics = (prepare_sa2_statistics_data()\n",
    "                      .to_csv(f'{output_file_path}sa2_statistics.csv', **write_options))\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# If called on to run as __main__\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1401eb40-ef86-4578-a25e-5227d63faa76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
